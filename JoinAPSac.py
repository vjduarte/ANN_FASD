# -*- coding: utf-8 -*-
"""Copy of SCCC_ANN

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tUIsypd6_b6hQuBVT4UaoaFImTf3bxoR
"""

# before proceeding further.
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tensorflow import feature_column

from tensorflow.keras import layers
from sklearn.model_selection import train_test_split
import pandas as pd
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras import backend as K
from tensorflow.keras import layers
from keras.layers import LeakyReLU

import logging
logger = tf.get_logger()
logger.setLevel(logging.ERROR)

ProASac = pd.read_csv(r"ProASac.csv")

def group_fix(s):
  if s == 1 :
    return 0
  return 1

ProASac['group']=ProASac .apply(lambda x: group_fix(x['group']), axis=1)


print(ProASac.shape)

train, test = train_test_split(ProASac, test_size=0.25)
train, val = train_test_split(train, test_size=0.20)
print(len(train), 'train examples')
print(len(val), 'validation examples')
print(len(test), 'test examples')
print(train)
x=train.drop(['group'], axis=1)
print(x)
y=train.iloc[:, 1]
print(y)
v_x=val.drop(['group'], axis=1)
x_t=test.drop(['group'], axis=1)
print(x)
y_t=test.iloc[:, 1]

def df_to_dataset(dataframe, shuffle=True, batch_size=32):
  dataframe = dataframe.copy()
  labels = dataframe.pop('group')
  ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))
  if shuffle:
    ds = ds.shuffle(buffer_size=len(dataframe))
  ds = ds.batch(batch_size)
  return ds

batch_size = 10 # A small batch sized is used for demonstration purposes
train_ds = df_to_dataset(train, batch_size=batch_size)
val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)
test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)

for feature_batch, label_batch in train_ds.take(1):
  print('Every feature:', list(feature_batch.keys()))
  print('A batch of ages:', feature_batch['age'])
  print('A batch of targets:', label_batch )

example_batch = next(iter(train_ds))[0]

# A utility method to create a feature column
# and to transform a batch of data
def demo(feature_column):
  feature_layer = layers.DenseFeatures(feature_column)

f1 = feature_column.numeric_column('f1')
demo(f1)

f2 = feature_column.numeric_column('f2')
demo(f2)

f3 = feature_column.numeric_column('f3')
demo(f3)

f4 = feature_column.numeric_column('f4')
demo(f4)

f5 = feature_column.numeric_column('f5')
demo(f5)

f6 = feature_column.numeric_column('f6')
demo(f6)

f7 = feature_column.numeric_column('f7')
demo(f7)

f8 = feature_column.numeric_column('f8')
demo(f8)

f9 = feature_column.numeric_column('f9')
demo(f9)

f10 = feature_column.numeric_column('f10')
demo(f10)

f11 = feature_column.numeric_column('f11')
demo(f11)

f12 = feature_column.numeric_column('f12')
demo(f12)

f13 = feature_column.numeric_column('f13')
demo(f13)

f14 = feature_column.numeric_column('f14')
demo(f14)

f15 = feature_column.numeric_column('f15')
demo(f15)

f16 = feature_column.numeric_column('f16')
demo(f16)

f17 = feature_column.numeric_column('f17')
demo(f17)

f18 = feature_column.numeric_column('f18')
demo(f18)

f19 = feature_column.numeric_column('f19')
demo(f19)

f20 = feature_column.numeric_column('f20')
demo(f20)

f21 = feature_column.numeric_column('f21')
demo(f21)

f22 = feature_column.numeric_column('f22')
demo(f22)

f23 = feature_column.numeric_column('f23')
demo(f23)

f24 = feature_column.numeric_column('f24')
demo(f24)

f25 = feature_column.numeric_column('f25')
demo(f25)

f26 = feature_column.numeric_column('f26')
demo(f26)

f27 = feature_column.numeric_column('f27')
demo(f27)

f28 = feature_column.numeric_column('f28')
demo(f28)

f29 = feature_column.numeric_column('f29')
demo(f29)

f30 = feature_column.numeric_column('f30')
demo(f30)

f31 = feature_column.numeric_column('f31')
demo(f31)

f32 = feature_column.numeric_column('f32')
demo(f32)

f33 = feature_column.numeric_column('f33')
demo(f33)

age = feature_column.numeric_column('age')
demo(age)

sex = feature_column.numeric_column('sex')
demo(sex)

feature_columns = []

# numeric cols
for header in ['age','sex','f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21', 'f22', 'f23', 'f24', 'f25', 'f26', 'f27', 'f28', 'f29', 'f30', 'f31', 'f32', 'f33']:
  feature_columns.append(feature_column.numeric_column(header))

feature_layer = tf.keras.layers.DenseFeatures(feature_columns)

batch_size = 32
train_ds = df_to_dataset(train, batch_size=batch_size)
val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)
test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)
train_ds

model = tf.keras.Sequential([
  feature_layer,
  layers.Dense(64, activation='sigmoid'),
  layers.Dense(32, activation='relu'),
  layers.Dropout(.1),
  layers.Dense(1)
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])
model.fit(train_ds,validation_data=val_ds,epochs=50)

loss, accuracy = model.evaluate(test_ds)
predictionsTest = model.predict(test_ds)
print("Accuracy: --->", accuracy)
#**************************************////////
